<!DOCTYPE html>
<html>

<head>
    <title>Documentazione.md</title>
    <meta http-equiv="Content-type" content="text/html;charset=UTF-8">
    
<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

html,footer,header{
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Custom MD PDF CSS
 */
html,footer,header{
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";

 }
body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>
<link rel="stylesheet" href="file:///r%3A/2.Travail/1.Enseignement/Cours/_1.Outils/2.Developpement/1.SCSS/main.css" type="text/css"><link rel="stylesheet" href="file:///d%3A/rdaros/Cours/_1.Outils/2.Developpement/1.SCSS/main.css" type="text/css">
</head>

<body>
    <h1 id="breast-cancer-classification">Breast Cancer Classification</h1>
<h3 id="autore">Autore</h3>
<p><a href="https://github.com/IXRyu">Fabio Zippo</a> - MAT 776951</p>
<p>email: fabiozippo03@hotmail.com</p>
<p>Occupazione: Studente presso l'Universit√† degli Studi di Bari <a href="https://www.uniba.it/it">Aldo Moro</a></p>
<h2 id="indice">Indice</h2>
<ul>
<li>
<h3 id="introduzione"><a href="#1---introduzione">Introduzione</a></h3>
<ul>
<li><a href="#11---il-tumore-al-seno">1.1 - Il tumore al seno</a></li>
<li><a href="#12---caratteristiche-principali-per-la-diagnosi">1.2 - Caratteristiche</a></li>
<li><a href="#13---obiettivo-del-progetto">1.3 - Obiettivo del Progetto</a></li>
</ul>
</li>
<li>
<h3 id="analisi-dataset"><a href="#2---analisi-dataset">Analisi Dataset</a></h3>
<ul>
<li><a href="#21---elenco-dati">2.1 - Elenco Dati</a></li>
<li><a href="#22---analisi-dei-dati">2.2 - Analisi dei Dati</a></li>
<li><a href="#23---pre-processing">2.3 - Preprocessing</a></li>
</ul>
</li>
<li>
<h3 id="apprendimento-supervisionato"><a href="">Apprendimento Supervisionato</a></h3>
<ul>
<li><a href="#approccio">Approccio</a></li>
<li><a href="#suddivisione-dei-dati">Suddivisione dei Dati</a></li>
<li><a href="#scelta-dei-modelli">Scelta dei Modelli</a></li>
<li><a href="#tuning-degli-iperparametri">Tuning degli Iperparametri</a></li>
<li><a href="#addestramento-dei-modelli">Addestramento &amp; Test dei Modelli</a></li>
<li><a href="#valutazione-dei-modelli">Valutazione dei Modelli</a></li>
<li><a href="#confronto-dei-modelli">Confronto dei Modelli</a>
<ul>
<li><a href="#decision-tree">Decision tree</a></li>
<li><a href="#random-forest">Random forest</a></li>
<li><a href="#logistic-regression">Logistic regression</a></li>
<li><a href="#support-vector-machine-svm">Support vector machine</a></li>
<li><a href="#artificial-neural-network-ann">Artificial neural network</a></li>
</ul>
</li>
<li><a href="#conclusioni">Conclusioni</a></li>
</ul>
</li>
<li>
<p><strong>Capitolo 3 - Ragionamento Probabilistico</strong></p>
<ul>
<li><a href="#motivazione">Motivazioni</a></li>
<li><a href="#approccio">Approccio</a></li>
<li><a href="#pareri-e-conclusioni">Pareri e conclusioni</a></li>
</ul>
</li>
<li>
<p><strong>Capitolo 4 - Knowledge Base</strong></p>
<ul>
<li><a href="#costruzione-della-knowledge-base">Costruzione della Knowledge Base</a></li>
<li><a href="#fatti-e-regole">Fatti e Regole</a></li>
<li><a href="#esempi-di-query">Esempi di query</a></li>
<li><a href="#possibili-upgrade">Upgrade</a></li>
</ul>
</li>
<li>
<p><strong>Capitolo 5 - Conclusioni</strong></p>
<ul>
<li><a href="#risultati-ottenuti">Risultati Ottenuti</a></li>
<li><a href="#possibili-sviluppi-futuri">Possibili Sviluppi Futuri</a></li>
</ul>
</li>
</ul>
<h2 id="1---introduzione">1 - Introduzione</h2>
<p>Il progetto ha come obiettivo la categorizzazione della natura, benigna o maligna, di un tumore al seno dati determinati fattori, utilizzando tecniche di machine learning. Il <a href="https://www.kaggle.com/datasets/merishnasuwal/breast-cancer-prediction-dataset">Dataset</a> utilizzato in questo progetto √® un dataset pubblico sul cancro al seno</p>
<h2 id="11---il-tumore-al-seno">1.1 - Il Tumore al Seno</h2>
<p>Il tumore al seno √® una delle principali cause di mortalit√† femminile a livello globale ed √® caratterizzato dalla crescita incontrollata di cellule anomale nei tessuti mammari. La diagnosi precoce √® fondamentale per migliorare le possibilit√† di trattamento e aumentare il tasso di sopravvivenza.</p>
<p>Per distinguere tra tumori benigni e maligni, i medici e i ricercatori analizzano una serie di caratteristiche ottenute attraverso esami, come la mammografia o l'analisi microscopica delle cellule tumorali. Queste feature includono propriet√† fisiche e strutturali delle cellule, che forniscono informazioni cruciali sulla natura del tumore.</p>
<h2 id="12---caratteristiche-principali-per-la-diagnosi">1.2 - Caratteristiche Principali per la Diagnosi</h2>
<p>Tra le principali feature utilizzate per la diagnosi troviamo:</p>
<ul>
<li><strong>Mean Radius (Raggio Medio)</strong>: Dimensione media delle cellule tumorali. I tumori maligni tendono ad avere un raggio maggiore rispetto a quelli benigni.</li>
<li><strong>Mean Perimeter (Perimetro Medio)</strong>: Misura del contorno delle cellule, utile per valutare la loro irregolarit√†.</li>
<li><strong>Mean Area (Area Media)</strong>: La superficie media delle cellule tumorali, spesso pi√π grande nei tumori maligni.</li>
<li><strong>Mean Texture (Testura Media)</strong>: Variazione dell'intensit√† nei pixel dell'immagine, utile per identificare anomalie nella struttura cellulare.</li>
<li><strong>Mean Smoothness (Morbidezza Media)</strong>: Indica quanto i bordi delle cellule sono regolari o frastagliati. I tumori maligni spesso mostrano bordi pi√π irregolari.</li>
</ul>
<h2 id="13---obiettivo-del-progetto">1.3 - Obiettivo del Progetto</h2>
<p>L'analisi di queste feature consente di addestrare modelli di intelligenza artificiale per classificare i tumori in benigni o maligni con un'elevata precisione. Tecniche di apprendimento supervisionato come:</p>
<ul>
<li><strong>Decision Tree</strong></li>
<li><strong>Random Forest</strong></li>
<li><strong>Support Vector Machines (SVM)</strong></li>
<li><strong>Logistic Regression</strong></li>
<li><strong>K-Nearest Neighbors (KNN)</strong></li>
</ul>
<p>insieme a modelli avanzati come <strong>Reti Neurali</strong> e <strong>Reti Bayesiane</strong>, possono essere utilizzate per migliorare l'affidabilit√† della diagnosi automatizzata.</p>
<p>L'obiettivo di questo progetto √® sviluppare e confrontare diversi modelli di classificazione per identificare con precisione la natura del tumore, fornendo un supporto utile ai medici nella diagnosi precoce del cancro al seno.</p>
<h3 id="2---analisi-dataset">2 - Analisi Dataset</h3>
<h2 id="21---elenco-dati">2.1 - Elenco Dati</h2>
<ul>
<li>Il dataset √® composto da 570 record e 6 Features.</li>
</ul>
<table>
<thead>
<tr>
<th><strong>Feature</strong></th>
<th><strong>Descrizione</strong></th>
<th><strong>Dominio</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>mean_radius</strong></td>
<td>Raggio medio delle cellule tumorali</td>
<td>Valori interi</td>
</tr>
<tr>
<td><strong>mean_perimeter</strong></td>
<td>Misura del contorno delle cellule</td>
<td>Valori interi</td>
</tr>
<tr>
<td><strong>mean_texture</strong></td>
<td>Variazione dell'intensit√† nei pixel dell'immagine</td>
<td>Valori interi</td>
</tr>
<tr>
<td><strong>mean_area</strong></td>
<td>La superficie media delle cellule tumorali</td>
<td>Valori interi</td>
</tr>
<tr>
<td><strong>mean_smoothness</strong></td>
<td>Indica quanto i bordi delle cellule sono regolari o frastagliati</td>
<td>Valori reali</td>
</tr>
<tr>
<td><strong>diagnosis</strong></td>
<td>Natura del tumore(benigna/maligna)</td>
<td>{0,1}</td>
</tr>
</tbody>
</table>
<h2 id="22---analisi-dei-dati">2.2 - Analisi dei Dati</h2>
<h3 id="matrice-di-correlazione-delle-feature">Matrice di Correlazione delle Feature</h3>
<p><img src="file:///z:/Studio/3^Anno/ICon/ICon-2025/img/Matrice_Correlazione.png" alt="Matrice_Correlazione"></p>
<p>Questa matrice di correlazione mostra le relazioni tra diverse feature estratte per la diagnosi del tumore al seno. La correlazione √® rappresentata da valori compresi tra 0 e 1:</p>
<ul>
<li><strong>1.0</strong> indica una forte dipendenza.</li>
<li><strong>0.0</strong> indica nessuna correlazione.</li>
</ul>
<p>I colori della matrice aiutano a visualizzare l'intensit√† delle correlazioni:</p>
<ul>
<li><strong>Rosso scuro</strong> rappresenta una forte correlazione.</li>
<li><strong>Blu</strong> rappresenta una correlazione pi√π debole.</li>
</ul>
<h2 id="osservazioni-principali">Osservazioni principali:</h2>
<ol>
<li>
<p><strong>Alta correlazione tra <code>mean_radius</code>, <code>mean_perimeter</code> e <code>mean_area</code></strong></p>
<ul>
<li>Questo suggerisce che il raggio, il perimetro e l'area sono caratteristiche altamente dipendenti e potrebbero ridondare nei modelli di machine learning, utile tener conto delle dipendenze per la rete Bayesiana</li>
</ul>
</li>
<li>
<p><strong>Correlazioni moderate con <code>mean_texture</code> e <code>mean_smoothness</code></strong></p>
</li>
</ol>
<p>Questa matrice aiuta a comprendere come le diverse caratteristiche sono legate tra loro, fornendo informazioni preziose per la selezione delle feature nei modelli di classificazione.</p>
<h3 id="pairplot">Pairplot</h3>
<p><img src="file:///z:/Studio/3^Anno/ICon/ICon-2025/img/pairplot.png" alt="pairplot"></p>
<p>Questa matrice di grafici a dispersione (<strong>pairplot</strong>) rappresenta le relazioni tra diverse feature del dataset utilizzato per la classificazione del tumore al seno. Le osservazioni sono colorate in base alla diagnosi:</p>
<ul>
<li><strong>Blu</strong> (1) indica tumori benigni.</li>
<li><strong>Rosso</strong> (0) indica tumori maligni.</li>
</ul>
<h3 id="osservazioni-principali">Osservazioni Principali:</h3>
<ol>
<li>
<p><strong>Distribuzioni univariate</strong></p>
<ul>
<li>Lungo la diagonale troviamo le distribuzioni di ogni singola feature.</li>
<li>Si nota che alcune variabili, come <code>mean_radius</code>, <code>mean_area</code> e <code>mean_perimeter</code>, mostrano una distribuzione differente tra tumori benigni e maligni.</li>
</ul>
</li>
<li>
<p><strong>Relazioni tra le variabili</strong></p>
<ul>
<li>Esistono forti correlazioni tra alcune variabili, in particolare tra <code>mean_radius</code>, <code>mean_area</code> e <code>mean_perimeter</code>.</li>
<li>La relazione tra <code>mean_radius</code> e <code>mean_area</code> appare quasi perfettamente lineare, il che suggerisce che una delle due potrebbe essere ridondante nei modelli di classificazione.</li>
</ul>
</li>
<li>
<p><strong>Separabilit√† tra classi</strong></p>
<ul>
<li>Alcune feature, come <code>mean_radius</code> e <code>mean_area</code>, sembrano offrire una buona separazione tra le classi, con i tumori maligni tendenti a valori pi√π elevati rispetto ai benigni.</li>
<li>Altre feature, come <code>mean_texture</code> e <code>mean_smoothness</code>, mostrano una maggiore sovrapposizione tra le due classi, suggerendo che da sole potrebbero non essere buoni predittori.</li>
</ul>
</li>
</ol>
<h3 id="utilit%C3%A0-per-la-modellizzazione">Utilit√† per la Modellizzazione:</h3>
<ul>
<li>Questo tipo di analisi √® utile per comprendere quali feature sono pi√π informative per la classificazione.</li>
<li>Potrebbe essere utile applicare tecniche di selezione delle feature o trasformazioni come PCA per ridurre la collinearit√† tra variabili fortemente correlate.</li>
</ul>
<h3 id="%F0%9F%93%8C-conclusione">üìå Conclusione:</h3>
<p>Il pairplot fornisce un'ottima panoramica delle relazioni tra feature e della distribuzione delle classi, aiutando a identificare quali variabili possono essere pi√π utili per i modelli di machine learning nella classificazione del tumore al seno.<br>
Ho ritenuto opportuno tenere le feature ridondanti per via della scarsa presenza di feature</p>
<h2 id="23---pre-processing">2.3 - Pre-Processing</h2>
<h2 id="preprocessing-dei-dati">Preprocessing dei Dati</h2>
<p>Il processo di <strong>preprocessing dei dati</strong> √® fondamentale per garantire che il dataset sia pulito, bilanciato e pronto per l'addestramento dei modelli di machine learning. Il codice implementa diverse operazioni di preprocessing, suddivise nei seguenti passaggi chiave:</p>
<ol>
<li>
<p><strong>Gestione dei valori mancanti</strong>:<br>
I dati vengono ripuliti rimuovendo eventuali valori mancanti (<code>NaN</code>), garantendo cos√¨ che il dataset sia completo e coerente.</p>
</li>
<li>
<p><strong>Normalizzazione delle feature</strong>:<br>
Per garantire che tutte le feature abbiano una scala comparabile, viene applicata una <strong>standardizzazione</strong> utilizzando lo <code>StandardScaler()</code>. Questo metodo trasforma ogni feature affinch√© abbia media zero e varianza unitaria, migliorando la stabilit√† dell'addestramento dei modelli.</p>
</li>
<li>
<p><strong>Suddivisione del dataset</strong>:<br>
I dati vengono divisi in <strong>training set (70%)</strong> e <strong>test set (30%)</strong> utilizzando <code>train_test_split()</code>. Questo passaggio √® essenziale per valutare le performance del modello su dati non visti.</p>
</li>
<li>
<p><strong>Espansione del dataset (opzionale)</strong>:<br>
√à presente una funzione <code>augment_dataset()</code> che genera dati sintetici moltiplicando alcune feature (<code>mean_radius</code>, <code>mean_smoothness</code>, <code>mean_perimeter</code>, <code>mean_area</code>, <code>mean_texture</code>) per dei fattori di scaling, con l'obiettivo di migliorare la robustezza del modello.</p>
</li>
</ol>
<p>Questo flusso di preprocessing assicura che il dataset sia pronto per l'addestramento di modelli di classificazione, migliorando la qualit√† e l'affidabilit√† dei risultati ottenuti.</p>
<h2 id="3---apprendimento-supervisionato---classificazione-binaria">3 - Apprendimento Supervisionato - Classificazione Binaria</h2>
<p>Questo progetto utilizza l'apprendimento supervisionato per creare modelli di classificazione binaria. L'obiettivo √® addestrare vari modelli di classificazione, ottimizzare i loro iperparametri e testare le loro prestazioni su un dataset di test.</p>
<h3 id="31---modelli-implementati">3.1 - Modelli Implementati</h3>
<p>I modelli utilizzati sono:</p>
<ul>
<li>
<p>Usati perch√® solidi con i problemi di classificazione binaria.</p>
<ul>
<li><strong>Support Vector Machine</strong>: √® un modello che cerca di trovare il miglior iperpiano che separa i dati in due classi.</li>
<li><strong>Logistic Regression</strong>: √® un modello di classificazione che si basa su una funzione logistica.</li>
</ul>
</li>
<li>
<p>Usati perch√® si vuole vedere se ci sono differenze significative tra i modelli.</p>
<ul>
<li><strong>Albero Decisionale</strong>: √® un modello che costruisce un albero di decisione in base alle features.</li>
<li><strong>Random Forest</strong>: √® un modello di classificazione che si basa su un insieme di alberi decisionali √® usato perch√© molte volte gli alberi decisionali sono molto sensibili ai dati e posso andare in overfitting.</li>
<li><strong>k-NN</strong>: √® un modello che classifica un punto dati in base alla maggioranza dei suoi vicini pi√π prossimi nel set di dati</li>
</ul>
</li>
<li>
<p><strong>SVM</strong> e <strong>Logistic Regression</strong> probabilmente performeranno meglio in questo problema e solitamente richiedono uno sforzo computazionale minore rispetto ad altri approcci.</p>
</li>
</ul>
<p>Invece:</p>
<ul>
<li><strong>Albero Decisionale</strong> pu√≤ presentare overfitting.</li>
<li><strong>Random Forest</strong> √® un modello composto da pi√π alberi decisionali per mitigare l' overfitting.</li>
<li><strong>k-NN</strong> potrebbe avere buone performance su dataset con confini decisionali semplici come questo</li>
</ul>
<h3 id="32---tuning-degli-iperparametri">3.2 - Tuning degli Iperparametri</h3>
<p>Per trovare i migliori iperparametri per i modelli ho utilizzato la tecnica di <strong>GridSearch</strong>, che esplora tutte le combinazioni possibili di iperparametri sebbene con alta complessit√† esponenziale, tuttavia il dataset √® molto piccolo ed √® quindi appropriato utilizzarlo</p>
<h3 id="33---addestramento">3.3 - Addestramento</h3>
<p>Ho addestrato i modelli sui dati attraverso la <strong>k-fold cross validation</strong> con <strong>k = 10</strong></p>
<p>Nell'apprendimento non c'√® stato un costo computazionale esagerato</p>
<h3 id="34---valutazione-dei-modelli">3.4 - Valutazione dei Modelli</h3>
<p>Per valutare i modelli ho utilizzato le seguenti metriche:</p>
<ul>
<li>Learning curve per osservare se il modello presenta overfitting o underfitting.
<ul>
<li><strong>Precision</strong>: √® la percentuale di predizioni positive fatte dal modello che sono corrette.</li>
<li><strong>Recall</strong>: √® la percentuale di predizioni positive corrette fatte dal modello rispetto a tutte le predizioni positive.</li>
<li><strong>F1</strong>: √® la media armonica tra precision e recall.</li>
</ul>
</li>
</ul>
<h3 id="35---confronto-modelli">3.5 - Confronto Modelli</h3>
<p>Per ogni modello si andr√† a mostrare:</p>
<ul>
<li><strong>Iperparametri</strong>: Impostati prima dell'allenamento e influenzano il processo di apprendimento</li>
<li><strong>Matrice di Confusione</strong>: Mostra la distribuzione di valori predetti e reali giusti e errati</li>
<li><strong>Metriche</strong>: Accuracy, Precision, Recall e F1</li>
<li><strong>Curva ROC</strong>: Receiver Operating Characteristic, si considera il grafico con il false positive rate sulle ascisse, le x, e del true positive rate sulle ordinate, i modelli peggiori in basso a destra</li>
<li><strong>Curva Precision-Recall</strong>: La precision √® sulle ascisse e la recall √® sulle ordinate. I modelli peggiori si trovano in basso a sinistra</li>
<li><strong>Learning Curve</strong>: Errore commesso all'aumentare del training size, per verificare overfitting</li>
</ul>
<h3 id="351---albero-decisionale">3.5.1 - Albero Decisionale</h3>
<h4 id="iperparametri">Iperparametri</h4>
<ul>
<li>
<p><strong><code>criterion</code></strong>: definisce la funzione di valutazione per la qualit√† della divisione nei nodi dell'albero. Pu√≤ essere:</p>
<ul>
<li><strong><code>gini</code></strong>: indice di Gini, misura l'impurit√† del nodo.</li>
<li><strong><code>entropy</code></strong>: entropia, misura l'incertezza della suddivisione.</li>
<li><strong><code>log_loss</code></strong>: log-loss, utilizzato per la regressione logistica.</li>
</ul>
</li>
<li>
<p><strong><code>max_depth</code></strong>: indica la profondit√† massima dell'albero, limitando il numero di livelli di nodi. Un valore pi√π alto consente pi√π complessit√†, ma rischia di causare overfitting.</p>
</li>
<li>
<p><strong><code>min_samples_split</code></strong>: stabilisce il numero minimo di campioni richiesti per dividere un nodo. Un valore maggiore riduce la complessit√† dell'albero, evitando suddivisioni troppo specifiche e migliorando la generalizzazione.</p>
</li>
</ul>
<h3 id="352---random-forest">3.5.2 - Random Forest</h3>
<h4 id="iperparametri">Iperparametri</h4>
<ul>
<li>
<p><strong><code>n_estimators</code></strong>: indica il numero di alberi nella foresta casuale. Maggiore √® il numero, migliore tende a essere la performance, ma aumenta anche il tempo di calcolo.</p>
</li>
<li>
<p><strong><code>max_depth</code></strong>: definisce la profondit√† massima di ogni albero nella foresta. Un valore maggiore pu√≤ portare a un modello pi√π complesso, ma pu√≤ anche causare overfitting.</p>
</li>
<li>
<p><strong><code>min_samples_split</code></strong>: stabilisce il numero minimo di campioni necessari per suddividere un nodo. Un valore pi√π alto evita suddivisioni troppo specifiche, migliorando la generalizzazione e riducendo l'overfitting.</p>
</li>
</ul>
<h3 id="353---logistic-regression">3.5.3 - Logistic Regression</h3>
<h4 id="iperparametri">Iperparametri</h4>
<ul>
<li>
<p><strong><code>penalty</code></strong>: specifica il tipo di regularizzazione da applicare.</p>
<ul>
<li><strong><code>l1</code></strong>: regularizzazione Lasso, che pu√≤ portare a modelli sparsi, eliminando alcune variabili.</li>
<li><strong><code>l2</code></strong>: regularizzazione Ridge, che riduce il peso delle variabili, ma non le elimina.</li>
</ul>
</li>
<li>
<p><strong><code>C</code></strong>: parametro di regularizzazione che controlla la forza della penalizzazione. Un valore pi√π basso indica una regularizzazione pi√π forte.</p>
<ul>
<li>Esempio: <strong>[0.001, 0.01, 0.1]</strong> indica che i valori possibili per <strong>C</strong> sono 0.001, 0.01 o 0.1.</li>
</ul>
</li>
<li>
<p><strong><code>solver</code></strong>: algoritmo utilizzato per ottimizzare il modello.</p>
<ul>
<li><strong><code>liblinear</code></strong>: un solver adatto per piccoli dataset e per penalizzazioni <strong>l1</strong> e <strong>l2</strong>.</li>
</ul>
</li>
<li>
<p><strong><code>max_iter</code></strong>: il numero massimo di iterazioni per la convergenza del modello. Un valore maggiore consente pi√π tentativi di ottimizzazione.</p>
<ul>
<li>Esempio: <strong>[100000, 150000]</strong> indica che il modello pu√≤ eseguire fino a 100.000 o 150.000 iterazioni.</li>
</ul>
</li>
</ul>
<h3 id="354---support-vector-machine">3.5.4 - Support Vector Machine</h3>
<h4 id="iperparametri">Iperparametri</h4>
<ul>
<li>
<p><strong><code>C</code></strong>: parametro di penalizzazione che controlla il trade-off tra un errore di classificazione pi√π basso e una superficie di decisione pi√π semplice. Un valore maggiore di <strong>C</strong> cerca di ridurre l'errore, ma pu√≤ portare a overfitting.</p>
<ul>
<li>Esempio: <strong>[0.01, 0.1, 1]</strong> indica che i valori possibili per <strong>C</strong> sono 0.01, 0.1 o 1.</li>
</ul>
</li>
<li>
<p><strong><code>kernel</code></strong>: il tipo di funzione di kernel utilizzata per trasformare i dati in uno spazio di dimensioni pi√π elevate.</p>
<ul>
<li><strong><code>linear</code></strong>: kernel lineare, adatto per dati separabili linearmente.</li>
<li><strong><code>rbf</code></strong>: kernel Radial Basis Function, molto usato per dati non lineari.</li>
<li><strong><code>poly</code></strong>: kernel polinomiale, utile per separazioni non lineari di grado superiore.</li>
<li><strong><code>sigmoid</code></strong>: kernel sigmoidale, simile alla funzione di attivazione di una rete neurale.</li>
</ul>
</li>
<li>
<p><strong><code>gamma</code></strong>: parametro che influisce sull'influenza di un singolo punto di dati per la costruzione della decision boundary.</p>
<ul>
<li><strong><code>scale</code></strong>: gamma √® impostato come <strong>1 / (n_features * X.var())</strong>, dove <strong>X.var()</strong> √® la varianza delle caratteristiche.</li>
<li><strong><code>auto</code></strong>: gamma √® impostato come <strong>1 / n_features</strong>.</li>
</ul>
</li>
</ul>
<h3 id="355---k-nearest-neighbour">3.5.5 - k-Nearest Neighbour</h3>
<h4 id="iperparametri">Iperparametri</h4>
<ul>
<li>
<p><strong><code>n_neighbors</code></strong>: indica il numero di vicini pi√π prossimi da considerare per la classificazione o la regressione.</p>
<ul>
<li>Esempio: <strong>[5]</strong> indica che il modello considera i 5 vicini pi√π prossimi.</li>
</ul>
</li>
<li>
<p><strong><code>weights</code></strong>: determina come ponderare i vicini durante la predizione.</p>
<ul>
<li><strong><code>distance</code></strong>: i vicini sono ponderati in base alla loro distanza dal punto di test, dando pi√π importanza ai vicini pi√π vicini.</li>
</ul>
</li>
<li>
<p><strong><code>algorithm</code></strong>: specifica l'algoritmo utilizzato per calcolare i vicini pi√π prossimi.</p>
<ul>
<li><strong><code>auto</code></strong>: il modello sceglie automaticamente l'algoritmo pi√π adatto (es. 'ball_tree', 'kd_tree', 'brute') in base alle caratteristiche del dataset.</li>
</ul>
</li>
<li>
<p><strong><code>p</code></strong>: parametro che definisce la distanza utilizzata per calcolare i vicini.</p>
<ul>
<li><strong><code>2</code></strong> indica la distanza Euclidea, che √® la misura di distanza pi√π comune.</li>
</ul>
</li>
<li>
<p><strong><code>n_jobs</code></strong>: determina il numero di processori da utilizzare per il calcolo parallelo.</p>
<ul>
<li><strong><code>1</code></strong> indica l'uso di un singolo processore.</li>
</ul>
</li>
</ul>

</body>

</html>